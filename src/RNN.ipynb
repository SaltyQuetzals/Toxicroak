{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "_kg_hide-output": false
      },
      "cell_type": "code",
      "source": "import sys, os, re, csv, codecs, numpy as np, pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport keras\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\nfrom keras.layers import Bidirectional, GlobalMaxPool1D\nfrom keras.models import Model, Sequential\nfrom keras import initializers, regularizers, constraints, optimizers, layers\nfrom keras.utils import plot_model\nfrom sklearn.metrics import classification_report\n\nfrom keras import metrics as keras_metrics",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3b47efd94e3d42500ed5651f651b6923d2691106"
      },
      "cell_type": "code",
      "source": "EMBEDDING_DIM = 200\nMAX_SEQ_LENGTH = 200\nMAX_FEATURES = 20000",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f9e0d9727d1865c8eeb7c57206f17b8b5f035755"
      },
      "cell_type": "code",
      "source": "def build_embedding_layer(word_index):\n    embeddings_index = {}\n    with open('../input/glove-global-vectors-for-word-representation/glove.6B.200d.txt') as f:\n        for line in f:\n            values = line.split()\n            word = values[0]\n            coefs = np.asarray(values[1:], dtype='float32')\n            embeddings_index[word] = coefs\n    embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n    for word, i in word_index.items():\n        embedding_vector = embeddings_index.get(word)\n        if embedding_vector is not None:\n            embedding_matrix[i] = embedding_vector\n    return Embedding(len(word_index)+1, \n                     EMBEDDING_DIM, \n                     weights=[embedding_matrix],\n                     input_length=MAX_SEQ_LENGTH,\n                     trainable=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "eab44ac385605e04f9273b792b239456f6f5cd4e"
      },
      "cell_type": "code",
      "source": "print(os.listdir('../input'))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "train = pd.read_csv('../input/augmented-toxicity/augmented_train.csv')\ntest = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/test.csv')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d1159f467fc637974653979c346f13ec6e92849a"
      },
      "cell_type": "code",
      "source": "LABEL_COLS = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\ny_train = train[LABEL_COLS].values\ntrain_sentences = train['comment_text']\ntest_sentences = test['comment_text']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "48dac2515021e3774e0d044f84fdb41c58c42684"
      },
      "cell_type": "code",
      "source": "tokenizer = Tokenizer(num_words=MAX_FEATURES)\ntokenizer.fit_on_texts(list(train_sentences))\ntokenized_train = tokenizer.texts_to_sequences(train_sentences)\ntokenized_test = tokenizer.texts_to_sequences(test_sentences)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "989977205a9cd3c5eda95e336dae2530027f29f3"
      },
      "cell_type": "code",
      "source": "X_train = pad_sequences(tokenized_train, maxlen=MAX_SEQ_LENGTH)\nX_test = pad_sequences(tokenized_test, maxlen=MAX_SEQ_LENGTH)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "134fc71ccaff8d0868ee274e455b3c8bd4400f50"
      },
      "cell_type": "code",
      "source": "model = Sequential([\n    build_embedding_layer(tokenizer.word_index),\n    LSTM(60, return_sequences=True, name='lstm'),\n    LSTM(120, return_sequences=True, name='lstm-2'),\n    GlobalMaxPool1D(),\n    Dropout(0.3),\n    Dense(50, activation='relu'),\n    Dropout(0.3),\n    Dense(6, activation='sigmoid')\n])\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=[keras_metrics.categorical_accuracy, keras_metrics.binary_accuracy])\n\nfrom IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\n\nSVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "28a1466081e52631dc185d52794c94cce9955b89"
      },
      "cell_type": "code",
      "source": "early_stopping=keras.callbacks.EarlyStopping(monitor='val_loss', patience=0, verbose=0, mode='auto')\nhistory = model.fit(X_train, y_train, epochs=3, batch_size=128, validation_split=0.33, callbacks=[early_stopping])\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-output": true,
        "trusted": true,
        "_uuid": "c2725f29714e00c13e812a69f08d6c98ccb47134"
      },
      "cell_type": "code",
      "source": "y_test_predictions = model.predict(X_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "eec3e114fb0b13ceff54417d8c81fe75d7d990ae"
      },
      "cell_type": "code",
      "source": "df = pd.DataFrame(y_test_predictions, columns=LABEL_COLS)\ndf['id'] = test['id']\ndf.describe()\ndf.to_csv('predicted_labels.csv', index=False)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}