{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-output": false,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model, Sequential\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.utils import plot_model\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from keras import metrics as keras_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3b47efd94e3d42500ed5651f651b6923d2691106"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 200\n",
    "MAX_SEQ_LENGTH = 200\n",
    "MAX_FEATURES = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f9e0d9727d1865c8eeb7c57206f17b8b5f035755"
   },
   "outputs": [],
   "source": [
    "def build_embedding_layer(word_index):\n",
    "    embeddings_index = {}\n",
    "    with open('../input/glove-global-vectors-for-word-representation/glove.6B.200d.txt') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return Embedding(len(word_index)+1, \n",
    "                     EMBEDDING_DIM, \n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=MAX_SEQ_LENGTH,\n",
    "                     trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "eab44ac385605e04f9273b792b239456f6f5cd4e"
   },
   "outputs": [],
   "source": [
    "print(os.listdir('../input'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/augmented-toxicity/augmented_train.csv')\n",
    "test = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d1159f467fc637974653979c346f13ec6e92849a"
   },
   "outputs": [],
   "source": [
    "LABEL_COLS = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "y_train = train[LABEL_COLS].values\n",
    "train_sentences = train['comment_text']\n",
    "test_sentences = test['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "48dac2515021e3774e0d044f84fdb41c58c42684"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_FEATURES)\n",
    "tokenizer.fit_on_texts(list(train_sentences))\n",
    "tokenized_train = tokenizer.texts_to_sequences(train_sentences)\n",
    "tokenized_test = tokenizer.texts_to_sequences(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "989977205a9cd3c5eda95e336dae2530027f29f3"
   },
   "outputs": [],
   "source": [
    "X_train = pad_sequences(tokenized_train, maxlen=MAX_SEQ_LENGTH)\n",
    "X_test = pad_sequences(tokenized_test, maxlen=MAX_SEQ_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "134fc71ccaff8d0868ee274e455b3c8bd4400f50"
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    build_embedding_layer(tokenizer.word_index),\n",
    "    LSTM(60, return_sequences=True, name='lstm'),\n",
    "    LSTM(120, return_sequences=True, name='lstm-2'),\n",
    "    LSTM(240, return_sequences=True, name='lstm-3'),\n",
    "    LSTM(60, return_sequences=True, name='lstm-4'),\n",
    "    GlobalMaxPool1D(),\n",
    "    Dropout(0.3),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(6, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[keras_metrics.categorical_accuracy, keras_metrics.binary_accuracy])\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "28a1466081e52631dc185d52794c94cce9955b89"
   },
   "outputs": [],
   "source": [
    "early_stopping=keras.callbacks.EarlyStopping(monitor='val_loss', patience=0, verbose=0, mode='auto')\n",
    "history = model.fit(X_train, y_train, epochs=15, batch_size=512, validation_split=0.33, callbacks=[early_stopping])\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "c2725f29714e00c13e812a69f08d6c98ccb47134"
   },
   "outputs": [],
   "source": [
    "y_test_predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "eec3e114fb0b13ceff54417d8c81fe75d7d990ae"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(y_test_predictions, columns=LABEL_COLS)\n",
    "df['id'] = test['id']\n",
    "df.describe()\n",
    "df.to_csv('predicted_labels.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
